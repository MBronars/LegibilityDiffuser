
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="bootstrap.js"></script>
<script type="text/javascript" charset="utf-8" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script> 
<!---
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
--->
<script src="load-mathjax.js" async></script>
<!-- Bootstrap CSS -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" rel="stylesheet">

<!-- Bootstrap JS and its dependencies (jQuery & Popper.js) -->
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>

<script>
    $(document).ready(function(){
      $('[data-toggle="tooltip"]').tooltip(); 
    });
  </script>
  
<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
}

@media screen and (min-width: 980px){
    body {
        width: 980px;
    }
}


h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #5364cc;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1 {
    text-align: center;
}
h2,h3 {
    text-align: left;
}

h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
h3 {
    font-weight: 600;
    margin: 16px 0px 4px 0px;
}

.paper-title {
    padding: 1px 0px 1px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-5 {
     width: 20%;
     float: left;
}

.move-down {
    margin-top:1.2cm;
}

.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.col-1 {
     width: 100%;
     float: left;
}

.author-row, .affil-row {
    font-size: 26px;
}

.author-row-new { 
    text-align: center; 
}

.author-row-new a {
    display: inline-block;
    font-size: 20px;
    padding: 4px;
}

.author-row-new sup {
    color: #313436;
    font-size: 12px;
}

.affiliations-new {
    font-size: 18px;
    text-align: center;
    width: 80%;
    margin: 0 auto;
    margin-bottom: 20px;
}

.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 26px;
}
.affiliatons {
    font-size: 18px;
}
.affil-row {
    margin-top: 18px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0; 
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    color: #666;
    margin-top: 4px;
    margin-bottom: 10px;
	text-align: left;
}


video {
    display: block;
    margin: auto;
}


figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    padding: 0;
    margin: 0;
    list-style: none;
}

.paper-btn-coming-soon {
    position: relative; 
    top: 0;
    left: 0;
}

.coming-soon {
    position: absolute;
    top: -15px;
    right: -15px;
}

.center {
  margin-left: 10.0%;
  margin-right: 10.0%;
}

.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #5364cc;
  color: white !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}
.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.paper-btn:hover {
    opacity: 0.85;
}

.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}

.venue {
    font-size: 23px;
}

.topnav {
    background-color: #EEEEEE;
    overflow: hidden;
}

.topnav div {
    max-width: 1070px;
    margin: 0 auto;
}

.topnav a {
    display: inline-block;
    color: black;
    text-align: center;
    vertical-align: middle;
    padding: 16px 16px;
    text-decoration: none;
    font-size: 18px;
}

.topnav img {
    padding: 2px 0px;
    width: 100%;
    margin: 0.2em 0px 0.3em 0px;
    vertical-align: middle;
}

pre {
    font-size: 0.9em;
    padding-left: 7px;
    padding-right: 7px;
    padding-top: 3px;
    padding-bottom: 3px;
    border-radius: 3px;
    background-color: rgb(235, 235, 235);
    overflow-x: auto;
}

.download-thumb {
    display: flex;
}

@media only screen and (max-width: 620px) {
    .download-thumb {
        display: none;
    }
}

.paper-stuff {
    width: 50%;
    font-size: 20px;
}

@media only screen and (max-width: 620px) {
    .paper-stuff {
        width: 100%;
    }
}
* {
  box-sizing: border-box;
}

.column {
  text-align: center;
  float: left;
  width: 16.666%;
  padding: 5px;
}
.column3 {
  text-align: center;
  float: left;
  width: 33.333%;
  padding: 5px;
}
.column4 {
  text-align: center;
  float: left;
  width: 50%;
  padding: 5px;
}
.column5 {
  text-align: center;
  float: left;
  width: 20%;
  padding: 5px;
}
.column10 {
  text-align: center;
  float: left;
  width: 10%;
  padding: 5px;
}
.border-right {
    border-right: 1px solid black;
}
.border-bottom{
    border-bottom: 1px solid black;
}


.row-center {
    margin: 16px 0px 16px 0px;
    text-align: center;
}

/* Clearfix (clear floats) */
.row::after {
  content: "";
  clear: both;
  display: table;
}
.img-fluid {
  max-width: 100%;
  height: auto;
}
.figure-img {
  margin-bottom: 0.5rem;
  line-height: 1;
}








.rounded-circle {
  border-radius: 50% !important;
}






/* Responsive layout - makes the three columns stack on top of each other instead of next to each other */
@media screen and (max-width: 500px) {
  .column {
    width: 100%;
  }
}
@media screen and (max-width: 500px) {
  .column3 {
    width: 100%;
  }
}

</style>
<link rel="stylesheet" href="bootstrap-grid.css">

<script type="text/javascript" src="../js/hidebib.js"></script>
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
    <head>
        <title>Legibility Diffuser: Offline Imitation for Intent Expressive Motion</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:description" content="Legibility Diffuser: Offline Imitation for Intent Expressive Motion"/>
        <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
    </head>

 <body>


<div class="container">
    <div class="paper-title">
    <h1> 
        Legibility Diffuser: Offline Imitation for Intent Expressive Motion
    </div>

    <div id="authors">
        <center>
            <div class="author-row-new">
                <a href="https://mbronars.github.io/">Matthew Bronars</a>,
                <a href="https://sites.google.com/view/shuocheng">Shuo Cheng</a>,
                <a href="https://faculty.cc.gatech.edu/~danfei/">Danfei Xu</a>
            </div>
        </center>
        <center>
        <div class="affiliations">
            <span>Georgia Institute of Technology</span>
        </div>

        <div class="affil-row">
            <div class="venue text-center"><b>RA-L (under submission)</b></div>
        </div>

        </center>

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="paper-btn" href="">
                <span class="material-icons"> description </span> 
                 Paper
            </a>
            <a class="paper-btn" href="">
                <span class="material-icons"> code </span>
                Code
            </a>  
            </div>
        </div>
    </div>
    <section id = "project-video">
        <center>
            <figure>
                <video class="centered" width="100%" controls playsinline class="video-background " >
                    <source src="materials/proj_vid.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </figure>

        </center>
    </section>
    <section id="teaser-image">
        <center>
            <figure>
                <a>
                    <img width="100%" src="materials/teaser.png">
                </a>
                <p class="caption">
                    Legibility Diffuser is an off-line imitation learning algorithm that can learn to generate the most legible modes from a multi-modal, multi-task dataset of human demonstrations.
                </p> <br>
            </figure>

        </center>
    </section>
    
    <!-- <section id="results-image">
        <center>
            <figure>
                <video class="centered" width="100%" autoplay loop muted playsinline class="video-background " >
                    <source src="materials/collage_tasks.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </figure>

        </center>
    </section> -->


    
    <section id="abstract">
        <h2>Abstract</h2>
        <div class="flex-row">
            <p>
                In human-robot collaboration, legible motion that
                conveys a robotâ€™s intentions and goals is known to improve
                safety, task efficiency, and user experience. Legible robot motion
                is typically generated using hand-designed cost functions and
                classical motion planners. However, with the rise of deep
                learning and data-driven robot policies, we need methods for
                training end-to-end on offline demonstration data. In this paper,
                we propose Legibility Diffuser, a diffusion-based policy that
                learns intent expressive motion directly from human demonstrations. By variably combining the noise predictions from a
                goal-conditioned diffusion model, we guide the robotâ€™s motion
                toward the most legible trajectory in the training dataset. We
                find that decaying the guidance weight over the course of the
                trajectory is critical for maintaining a high success rate while
                maximizing legibility.
            </p>
        </div>
    </section>

    <section id="Method">
        <h2>Method</h2>
        <div class="flex-row">
            <p>
                In human-robot collaboration, legible motion that
                conveys a robotâ€™s intentions and goals is known to improve
                safety, task efficiency, and user experience. Legible robot motion
                is typically generated using hand-designed cost functions and
                classical motion planners. However, with the rise of deep
                learning and data-driven robot policies, we need methods for
                training end-to-end on offline demonstration data. In this paper,
                we propose Legibility Diffuser, a diffusion-based policy that
                learns intent expressive motion directly from human demonstrations. By variably combining the noise predictions from a
                goal-conditioned diffusion model, we guide the robotâ€™s motion
                toward the most legible trajectory in the training dataset. We
                find that decaying the guidance weight over the course of the
                trajectory is critical for maintaining a high success rate while
                maximizing legibility.
            </p>
        </div>
    </section>

    <section id="teaser-image">
        <center>
            <figure>
                <a>
                    <img width="100%" src="materials/LD.png">
                </a>
                <p class="caption">
                    This diagram shows the evaluation process for Legibility Diffuser. At each step, the model takes as input a sequence of \( \tau_s \) states as well as a target goal \( g^* \) and an opposing goal \( g^- \). While generating a sequence of actions, we use diffusion model guidance to ensure that we imitate the most legible actions from the training data. This is controlled by the guidance weight \( w_t \) and the ratio term \( \alpha \) which determines the portion of negative guidance that goes to \( g^- \) versus \( \emptyset \). Once the actions are generated, we carry out \( \tau_a \) of the \( \tau_p \) predicted actions in open loop. The guidance weight is decayed by \( \gamma \) before generating the next set of actions.
                </p> <br>
            </figure>

        </center>
    </section>


    <section id="results">
        <hr>
        <h2>Block Reach Experiments</h2>
        <figure>
            <a>
                <img width="100%" src="materials/teaser.png">
            </a>
            <p class="caption">
                Accomplished goals at the end of 5 different evaluation episodes along training in the real world.
            </p> <br>
        </figure>
        <h2>Selective Interaction Experiments</h2>  
            <figure>
                <a>
                    <img width="100%" src="materials/teaser.png">
                </a>
                <p class="caption">
                    Six simulation benchmarks where we test HuGE and compare against baselines. <strong>Bandu</strong>, <strong>Block Stacking</strong>, <strong>Kitchen</strong>, and <strong>Pusher</strong>, are long-horizon manipulation tasks; <strong>Four rooms</strong> and <strong>Maze</strong> are 2D navigation tasks
                </p> <br>
            </figure>
            <figure>
                <a>
                    <img width="100%" src="materials/teaser.png">
                </a>
                <p class="caption">
                    Success curves of HuGE on the proposed benchmarks compared to the baselines. 
                    HuGE outperforms the rest of the baselines, some of which cannot solve the environment, while converging to the oracle accuracy. 
                    For those curves that are not visible, it means they never succeeded and hence are all at 0 (see D.9 in the paper for distance curves). 
                    Note the lexa-like benchmark is only computed in the four rooms benchmark. The curves are the average of 4 runs, and the shaded region corresponds to the standard deviation. 
                </p> <br>
            </figure>
            

        <h2>Crowdsourced Experiments</h2>
        <figure>
            <a>
                <img width="100%" src="materials/website_figures_crowdsourcing.png">
            </a>
            <p class="caption">
                <strong>left</strong>: Crowdsourcing experiment learning curves for the kitchen, <strong>middle</strong>: human annotators spanned 3 continents and 13 countries, <strong>right</strong>: screenshot of the interface for data collection.
            </p> <br>
        </figure>
        
    </section> 
    
    <section id="robust_noise">
        <hr>
        <h2>Robustness to Learning from Noisy Human Feedback</h2>
        <center>
        <figure>
            <video class="centered" width="100%" autoplay loop muted playsinline class="video-background " >
                <source src="materials/huge_explained_rl.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </figure>

    </section>

    <section id="analysis">
        <hr>
        <h2>Analysis</h2>
        <figure>
            <a>
                <img width="100%" src="materials/website_figures_analysis.png">
            </a>
            <p class="caption">
                <strong>left</strong>: Learning a goal selector (<i>Ours</i>) needs on average 50% fewer labels than not (<i>DDL</i>) 
                <strong>middle</strong>: As the noise in the feedback increases, so will the number of timesteps to succeed, however HuGE still finds a solution. 
                <strong>right</strong>: HuGE is robust to noisy goal selectors since trajectories going to each mode will be sampled while if we ran RL the policy would become biased and fail. 
                See Appendix E in the paper for more details.
            </p> <br>
        </figure>        
        <hr>

    </section> 

    <!--
    <section id="paper">

        <h2>Team</h2>        
        <div class="row">
            <div class="column5">
                <a href='https://marceltorne.github.io/'>
                    <img  src=./materials/people/marcel.png class="figure-img img-fluid rounded-circle" height=200px width=200px>
                </a>
                <p class=profname> Marcel Torne Villasevil </p>
                <p class=institution>Harvard University, MIT</p>
            </div>

            <div class="column5">
                <a href=''>
                    <img  src=./materials/people/max.png class="figure-img img-fluid rounded-circle" height=200px width=200px>
                </a>
                <p class=profname> Max Balsells i Pamies </p>
                <p class=institution>University of Washington</p>
            </div>

            <div class="column5">
                <a href='https://taochenshh.github.io'>
                    <img  src=./materials/people/tao.png class="figure-img img-fluid rounded-circle" height=200px width=200px>
                </a>
                <p class=profname> Tao Chen </p>
                <p class=institution>MIT</p>
            </div>
            <div class="column5">
                <a href='https://people.eecs.berkeley.edu/~pulkitag/'>
                    <img  src=./materials/people/pulkit.png class="figure-img img-fluid rounded-circle" height=200px width=200px>
                </a>
                <p class=profname> Pulkit Agrawal </p>
                <p class=institution>MIT</p>
            </div>



            <center>
                <div class="column0">
                    <a href="https://abhishekunique.github.io">
                        <img src=./materials/people/abhishek.png class="figure-img img-fluid rounded-circle" height=200px width=200px>
                    </a>
                    <p class=profname> Abhishek Gupta </p>
                    <p class=institution>University of Washington</p>
                </div>

                <div class="column0">
                    <a href='https://people.eecs.berkeley.edu/~pulkitag/'>
                        <img  src=./materials/people/pulkit.png class="figure-img img-fluid rounded-circle" height=200px width=200px>
                    </a>
                    <p class=profname> Pulkit Agrawal </p>
                    <p class=institution>MIT</p>
                </div>
    
                <div class="column0">
                    <a href="https://abhishekunique.github.io">
                        <img src=./materials/people/abhishek.png class="figure-img img-fluid rounded-circle" height=200px width=200px>
                    </a>
                    <p class=profname> Abhishek Gupta </p>
                    <p class=institution>University of Washington</p>
                </div>

            </center>

         </div>

    </section>



    -->

   
    <section>
        This webpage template was recycled from <a href='https://nv-tlabs.github.io/LION/'>here</a>.
    </section>
    


</div>
</body>
</html>
