
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="bootstrap.js"></script>
<script type="text/javascript" charset="utf-8" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script> 
<!---
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
--->
<script src="load-mathjax.js" async></script>
<!-- Bootstrap CSS -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" rel="stylesheet">

<!-- Bootstrap JS and its dependencies (jQuery & Popper.js) -->
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>

<script>
    $(document).ready(function(){
      $('[data-toggle="tooltip"]').tooltip(); 
    });
  </script>
  
<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
}

@media screen and (min-width: 980px){
    body {
        width: 980px;
    }
}


h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #5364cc;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1 {
    text-align: center;
}
h2,h3 {
    text-align: left;
}

h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
h3 {
    font-weight: 600;
    margin: 16px 0px 4px 0px;
}

.paper-title {
    padding: 1px 0px 1px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-5 {
     width: 20%;
     float: left;
}

.move-down {
    margin-top:1.2cm;
}

.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.col-1 {
     width: 100%;
     float: left;
}

.author-row, .affil-row {
    font-size: 26px;
}

.author-row-new { 
    text-align: center; 
}

.author-row-new a {
    display: inline-block;
    font-size: 20px;
    padding: 4px;
}

.author-row-new sup {
    color: #313436;
    font-size: 12px;
}

.affiliations-new {
    font-size: 18px;
    text-align: center;
    width: 80%;
    margin: 0 auto;
    margin-bottom: 20px;
}

.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 26px;
}
.affiliatons {
    font-size: 18px;
}
.affil-row {
    margin-top: 18px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0; 
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    color: #666;
    margin-top: 4px;
    margin-bottom: 10px;
	text-align: left;
}


video {
    display: block;
    margin: auto;
}


figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    padding: 0;
    margin: 0;
    list-style: none;
}

.paper-btn-coming-soon {
    position: relative; 
    top: 0;
    left: 0;
}

.coming-soon {
    position: absolute;
    top: -15px;
    right: -15px;
}

.center {
  margin-left: 10.0%;
  margin-right: 10.0%;
}

.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #5364cc;
  color: white !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}
.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.paper-btn:hover {
    opacity: 0.85;
}

.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}

.venue {
    font-size: 23px;
}

.topnav {
    background-color: #EEEEEE;
    overflow: hidden;
}

.topnav div {
    max-width: 1070px;
    margin: 0 auto;
}

.topnav a {
    display: inline-block;
    color: black;
    text-align: center;
    vertical-align: middle;
    padding: 16px 16px;
    text-decoration: none;
    font-size: 18px;
}

.topnav img {
    padding: 2px 0px;
    width: 100%;
    margin: 0.2em 0px 0.3em 0px;
    vertical-align: middle;
}

pre {
    font-size: 0.9em;
    padding-left: 7px;
    padding-right: 7px;
    padding-top: 3px;
    padding-bottom: 3px;
    border-radius: 3px;
    background-color: rgb(235, 235, 235);
    overflow-x: auto;
}

.download-thumb {
    display: flex;
}

@media only screen and (max-width: 620px) {
    .download-thumb {
        display: none;
    }
}

.paper-stuff {
    width: 50%;
    font-size: 20px;
}

@media only screen and (max-width: 620px) {
    .paper-stuff {
        width: 100%;
    }
}
* {
  box-sizing: border-box;
}

.column {
  text-align: center;
  float: left;
  width: 16.666%;
  padding: 5px;
}
.column3 {
  text-align: center;
  float: left;
  width: 33.333%;
  padding: 5px;
}
.column4 {
  text-align: center;
  float: left;
  width: 50%;
  padding: 5px;
}
.column5 {
  text-align: center;
  float: left;
  width: 20%;
  padding: 5px;
}
.column10 {
  text-align: center;
  float: left;
  width: 10%;
  padding: 5px;
}
.border-right {
    border-right: 1px solid black;
}
.border-bottom{
    border-bottom: 1px solid black;
}


.row-center {
    margin: 16px 0px 16px 0px;
    text-align: center;
}

/* Clearfix (clear floats) */
.row::after {
  content: "";
  clear: both;
  display: table;
}
.img-fluid {
  max-width: 100%;
  height: auto;
}
.figure-img {
  margin-bottom: 0.5rem;
  line-height: 1;
}








.rounded-circle {
  border-radius: 50% !important;
}






/* Responsive layout - makes the three columns stack on top of each other instead of next to each other */
@media screen and (max-width: 500px) {
  .column {
    width: 100%;
  }
}
@media screen and (max-width: 500px) {
  .column3 {
    width: 100%;
  }
}

</style>
<link rel="stylesheet" href="bootstrap-grid.css">

<script type="text/javascript" src="../js/hidebib.js"></script>
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
    <head>
        <title>Legibility Diffuser: Offline Imitation for Intent Expressive Motion</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:description" content="Legibility Diffuser: Offline Imitation for Intent Expressive Motion"/>
        <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
    </head>

 <body>


<div class="container">
    <div class="paper-title">
    <h1> 
        Legibility Diffuser: Offline Imitation for Intent Expressive Motion
    </div>

    <div id="authors">
        <center>
            <div class="author-row-new">
                <a href="https://mbronars.github.io/">Matthew Bronars</a>,
                <a href="https://sites.google.com/view/shuocheng">Shuo Cheng</a>,
                <a href="https://faculty.cc.gatech.edu/~danfei/">Danfei Xu</a>
            </div>
        </center>
        <center>
        <div class="affiliations">
            <span>Georgia Institute of Technology</span>
        </div>

        <div class="affil-row">
            <div class="venue text-center"><b>RA-L (under submission)</b></div>
        </div>

        </center>

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="paper-btn" href="">
                <span class="material-icons"> description </span> 
                 Paper
            </a>
            <a class="paper-btn" href="">
                <span class="material-icons"> code </span>
                Code
            </a>  
            </div>
        </div>
    </div>
    <section id = "project-video">
        <center>
            <figure>
                <video class="centered" width="100%" controls playsinline class="video-background " >
                    <source src="materials/proj_vid.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </figure>

        </center>
    </section>
    <section id="teaser-image">
        <center>
            <figure>
                <a>
                    <img width="100%" src="materials/teaser.png">
                </a>
                <p class="caption">
                    Legibility Diffuser is an off-line imitation learning algorithm that can learn to generate the most legible modes from a multi-modal, multi-task dataset of human demonstrations.
                </p> <br>
            </figure>

        </center>
    </section>
    
    <!-- <section id="results-image">
        <center>
            <figure>
                <video class="centered" width="100%" autoplay loop muted playsinline class="video-background " >
                    <source src="materials/collage_tasks.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </figure>

        </center>
    </section> -->


    
    <section id="abstract">
        <h2>Abstract</h2>
        <div class="flex-row">
            <p>
                In human-robot collaboration, legible motion that
                conveys a robotâ€™s intentions and goals is known to improve
                safety, task efficiency, and user experience. Legible robot motion
                is typically generated using hand-designed cost functions and
                classical motion planners. However, with the rise of deep
                learning and data-driven robot policies, we need methods for
                training end-to-end on offline demonstration data. In this paper,
                we propose Legibility Diffuser, a diffusion-based policy that
                learns intent expressive motion directly from human demonstrations. By variably combining the noise predictions from a
                goal-conditioned diffusion model, we guide the robotâ€™s motion
                toward the most legible trajectory in the training dataset. We
                find that decaying the guidance weight over the course of the
                trajectory is critical for maintaining a high success rate while
                maximizing legibility.
            </p>
        </div>
    </section>

    <section id="Method">
        <h2>Method</h2>
        <div class="flex-row">
            <p>
                This paper establishes a connection between legible motion and conditional generative models.  
                A critical feature of realistic human demonstrations is that they are multi-task and multi-modal; they show multiple ways of accomplishing a task or reaching a goal.  
                Our key insight is that we can generate intent expressive motion by directly imitating the most legible mode from a diverse dataset of human demonstrations.  
                Specifically, we introduce Legibility Diffuser, a conditional generative policy that produces legible robot motion through diffusion model guidance.  
                Our end-to-end method does not require estimating cost functions, classical motion planning, or any labeling of the training dataset.
                We evaluate the legibility of our methods across four experiments, including a long-horizon manipulation task, and a real robot evaluation.
            </p>
        </div>
    </section>

    <section id="main-diagram">
        <center>
            <figure>
                <a>
                    <img width="100%" src="materials/LD.png">
                </a>
                <p class="caption">
                    This diagram shows the evaluation process for Legibility Diffuser. 
                    At each step, the model takes as input a sequence of \( \tau_s \) states as well as a target goal \( g^* \) 
                    and an opposing goal \( g^- \). While generating a sequence of actions, 
                    we use diffusion model guidance to ensure that we imitate the most legible actions from the training data. 
                    This is controlled by the guidance weight \( w_t \) and the ratio term \( \alpha \) 
                    which determines the portion of negative guidance that goes to \( g^- \) versus \( \emptyset \). 
                    Once the actions are generated, we carry out \( \tau_a \) of the \( \tau_p \) predicted actions in open loop. 
                    The guidance weight is decayed by \( \gamma \) before generating the next set of actions.
                </p> <br>
            </figure>
        </center>
    </section>


    <section id="results">
        <hr>
        <h2>Block Reach Experiments</h2>
            <div class="flex-row">
                <p>
                    This task is based on a frequently used
                    legibility experiment [1]. Two blocks are placed next to eachother on a table, a robot arm is positioned on the other end
                    of the table. The robot reaches for one of the blocks and lifts
                    it. Assume there is an observer. If the agent moves directly
                    towards the blocks, it is unclear if the target is the left block
                    or the right block. If the agent takes a trajectory that swings
                    wide to one side, then g*
                    can be easily predicted. These wide
                    trajectories are the legible trajectories.
                </p>
            </div>
            <figure>
                <video class="centered" width="100%" muted loop autoplay playsinline class="video-background " >
                    <source src="materials/block_reach.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <p class="caption">
                    Rollouts for block reach real.
                </p> <br>
            </figure>
        <h2>Selective Interaction Experiments</h2>  
            <div class="flex-row">
                <p>
                    In this task, there are $m$ objects in a scene {$o_1, o_2, ..., o_m$} and each object has a corresponding goal position.  The robot must move $n < m$ objects to their goal positions (within tolerance $\epsilon_{tol}$).  A goal $g$ can be described by this set of $n$ objects. $g^*$ and $g^-$ have $n-1$ objects in common; there is only one distinguishing object.  We define $o^*$ as the distinguishing object for $g^*$ and $o^-$ as the distinguishing object for $g^-$.  For example, if $g^* = \{o_1, o_2, o_3\}$ and $g^- = \{o_1, o_2, o_4\}$, $o^* = o_3$  and  $o^- = o_4$.  A legible agent \emph{should} interact with $o^*$ early in the trajectory so that an observe can quickly predict the target goal.  A legible agent \emph{should not} interact with $o^-$ as this would confuse the observer, resulting in an incorrect goal prediction.  This task evaluates long horizon legibility. We adapt the Franka Kitchen environment and dataset for selective interaction.
                </p>
            </div>
            <figure>
                <video class="centered" width="100%" muted loop autoplay playsinline class="video-background " >
                    <source src="materials/selective_interaction.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <p class="caption">
                    Rollouts for Selective Interaction Medium. 
                </p> <br>
            </figure>

        <h2>Results - Legibility</h2>
        <figure>
            <a>
                <img width="100%" src="materials/Trajs.png">
            </a>
            <p class="caption">
                50 rollouts of Legibiltiy Diffuser and baselines in simulation.  C-Bet and Diffusion Policy capture the entire training data distribution, IBC collapses on an arbitrary mode, Legibility Diffuser collapses on the most legible mode. 
            </p> <br>
        </figure>
        <figure>
            <a>
                <img width="100%" src="materials/LegibilityResults.png">
            </a>
            <p class="caption">
                Legibility scores for our model and baselines averaged over $50$ seeds.  These scores are calculated using the legibility heuristics. Block reach real is averaged over $3$ seeds and $30$ demonstrations. 
            </p> <br>
        </figure>

        <h2>Results - Success Rate</h2>
        <figure>
            <a>
                <img width="100%" src="materials/SuccessResults.png">
            </a>
            <p class="caption">
                Success rate of our model and baselines averaged over 50 seeds.  For selective interaction we report the average number of object interactions.  Block reach real is averaged over $3$ seeds and $30$ demonstrations. 
            </p> <br>
        </figure>
        
    </section> 
    
    <section id="ablations">
        <figure>
            <a>
                <img width="100%" src="materials/AlphaLeg.png">
            </a>
            <p class="caption">
                We ablate over $\alpha$ while varying guidance weight $w$ 
                (Refer to methods section).  $\alpha \approx 1$ gives us a high 
                legibility on both tasks across all of the guidance weights. 
            </p> <br>
        </figure>
        <figure>
            <a>
                <img width="100%" src="materials/AlphaSuc.png">
            </a>
            <p class="caption">
                We ablate over $\alpha$ while varying guidance weight $w$ (Refer to methods section). 
                For most guidance weights, success rate is not particularly sensitive to $\alpha$. 
            </p> <br>
        </figure>
        <figure>
            <a>
                <img width="100%" src="materials/GammaLeg.png">
            </a>
            <p class="caption">
                We ablate over $\gamma$ while varying guidance weight $w$ (Eq. \ref{eq: Legibility Guidance}).  
                $\gamma \rightarrow 1$ leads to higher legibility as long as success rate is maintained. 
            </p> <br>
        </figure>
        <figure>
            <a>
                <img width="100%" src="materials/GammaSuc.png">
            </a>
            <p class="caption">
                We ablate over $\gamma$ while varying guidance weight $w$ (Eq. \ref{eq: Legibility Guidance}).  
                Across all guidance weights we see that success rate decreases as $\gamma \rightarrow 1$. 
            </p> <br>
        </figure>

    </section>

    <section id="analysis">
        <hr>
        <h2>Analysis</h2>
        <div class="flex-row">
            <p>
                Legibility Diffuser is able to produce legible robot motion without any hand-designed cost functions, dataset labeling, or classical motion planning.  
                Optimizing for legibility does not sacrifice success rate.  
                Increasing guidance weight increases legibility.  
                Time-varying guidance weight is a critical component of Legibility Diffuser.
                Negitive guidance on opposing goal is helpful for Legibility Diffuser.
            </p>
        </div>
  
        <hr>

    </section> 

    <!--
    <section id="paper">

        <h2>Team</h2>        
        <div class="row">
            <div class="column5">
                <a href='https://marceltorne.github.io/'>
                    <img  src=./materials/people/marcel.png class="figure-img img-fluid rounded-circle" height=200px width=200px>
                </a>
                <p class=profname> Marcel Torne Villasevil </p>
                <p class=institution>Harvard University, MIT</p>
            </div>

            <div class="column5">
                <a href=''>
                    <img  src=./materials/people/max.png class="figure-img img-fluid rounded-circle" height=200px width=200px>
                </a>
                <p class=profname> Max Balsells i Pamies </p>
                <p class=institution>University of Washington</p>
            </div>

            <div class="column5">
                <a href='https://taochenshh.github.io'>
                    <img  src=./materials/people/tao.png class="figure-img img-fluid rounded-circle" height=200px width=200px>
                </a>
                <p class=profname> Tao Chen </p>
                <p class=institution>MIT</p>
            </div>
            <div class="column5">
                <a href='https://people.eecs.berkeley.edu/~pulkitag/'>
                    <img  src=./materials/people/pulkit.png class="figure-img img-fluid rounded-circle" height=200px width=200px>
                </a>
                <p class=profname> Pulkit Agrawal </p>
                <p class=institution>MIT</p>
            </div>



            <center>
                <div class="column0">
                    <a href="https://abhishekunique.github.io">
                        <img src=./materials/people/abhishek.png class="figure-img img-fluid rounded-circle" height=200px width=200px>
                    </a>
                    <p class=profname> Abhishek Gupta </p>
                    <p class=institution>University of Washington</p>
                </div>

                <div class="column0">
                    <a href='https://people.eecs.berkeley.edu/~pulkitag/'>
                        <img  src=./materials/people/pulkit.png class="figure-img img-fluid rounded-circle" height=200px width=200px>
                    </a>
                    <p class=profname> Pulkit Agrawal </p>
                    <p class=institution>MIT</p>
                </div>
    
                <div class="column0">
                    <a href="https://abhishekunique.github.io">
                        <img src=./materials/people/abhishek.png class="figure-img img-fluid rounded-circle" height=200px width=200px>
                    </a>
                    <p class=profname> Abhishek Gupta </p>
                    <p class=institution>University of Washington</p>
                </div>

            </center>

         </div>

    </section>



    -->

   
    <section>
        This webpage template was recycled from <a href='https://nv-tlabs.github.io/LION/'>here</a>.
    </section>
    


</div>
</body>
</html>
